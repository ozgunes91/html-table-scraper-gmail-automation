# HTML Table Scraper â†’ Excel Generator â†’ Email Automation  
*A small, end-to-end automation pipeline built with Python, GitHub Actions and n8n.*

---

## ğŸ§© Project Story

This project was created to automatically extract an HTML table from the web, clean it, convert it into a polished Excel file, and make it easily deliverable through different automation channels.

The goal is simple:

**â€œFetch data â†’ Clean it â†’ Convert to Excel â†’ Deliver it â€” with one click or fully automated.â€**

The pipeline demonstrates a modular structure that can adapt to multiple execution styles depending on user needs.

---

## âš™ï¸ Core Methodology

This automation consists of three independent but compatible components:

1. **Python script**  
   - Scrapes an HTML table  
   - Cleans and normalizes the data  
   - Converts it into Excel  
   - Sends the Excel via Gmail (if credentials are configured)

2. **GitHub Actions workflow**  
   - Executes the same Python script in a clean cloud environment  
   - Publishes the resulting Excel as an Artifact  
   - Can be triggered manually from the Actions tab

3. **n8n workflow**  
   - Can trigger the GitHub Actions workflow  
   - Downloads the latest Excel artifact  
   - Makes the Excel file downloadable inside n8n  
   - Optionally emails the file again  
   - Can run on a schedule (e.g., daily delivery)

This gives flexibility for different user types:
- Developers â†’ use GitHub Actions  
- Non-technical users â†’ use n8n  
- Local testing â†’ run Python script directly

---

# ğŸ§  Architecture Overview

```
Wikipedia Page
        â”‚
        â–¼
  Python Script
  (scrape â†’ parse â†’ clean â†’ Excel â†’ email)
        â”‚
        â”‚  (optional: triggered in the cloud)
        â–¼
 GitHub Actions Workflow
  - Runs python script
  - Publishes Excel as Artifact
        â”‚
        â–¼
        n8n
  - Triggers workflow (manual or scheduled)
  - Fetches latest Artifact
  - Downloads Excel
  - Sends email (optional)
  - Exposes Excel as downloadable output
```

This architecture matches **exactly** how the project works in reality.

---

# ğŸ 1. Python Script (Real Functional Steps)

File: `html_table_scraper.py`  
A fully functional pipeline consisting of 5 real stages:

### âœ” 1. Fetch HTML  
- Uses `requests`  
- Custom User-Agent + timeout for reliability  
- Downloads raw HTML from the Wikipedia page

### âœ” 2. Parse first HTML `<table>`  
- `BeautifulSoup` locates the table  
- `pandas.read_html` parses it into a DataFrame

### âœ” 3. Clean the DataFrame  
The script performs **real cleaning logic**:

- Flattens MultiIndex columns  
- Normalizes column names  
- Renames messy technical names to human-friendly ones  
  - `revenue_usd_in_millions` â†’ `revenue_usd_million`  
  - `employees_employees` â†’ `employees`  
  - `headquartersnote_1` â†’ `headquarters`
- Removes â€œunnamedâ€ columns  
- Drops blank rows  
- Removes optional columns (`state_owned`, `reference`) if present  
- Sorts by `rank` column when available  

### âœ” 4. Save Excel  
Saves the cleaned DataFrame automatically to:

```
outputs/largest_companies_by_revenue.xlsx
```

### âœ” 5. Gmail Email Send  
- Uses `smtp.gmail.com:587`  
- Loads credentials from `.env`  
- If credentials missing â†’ prints warning and skips email  
- Otherwise â†’ sends the Excel file as an email attachment

The script alone provides a complete â€œscrape â†’ clean â†’ Excel â†’ emailâ€ pipeline.

---

# ğŸŸ¦ 2. GitHub Actions Workflow (automation.yml)

The repository includes:

```
.github/workflows/automation.yml
```

This workflow:

- Installs Python + dependencies  
- Runs the same Python script in the cloud  
- Generates the Excel file  
- Publishes it as a **GitHub Artifact**  
- Is triggered manually via **Run workflow**  
- Does **not** include cron (optional)

This makes the pipeline reproducible and cloud-ready.

---

# ğŸŸ© 3. n8n Workflow

Stored under `docs/html-table-scraper-gmail-automation.json`.

The real n8n workflow performs:

1. Triggers the GitHub Actions workflow (workflow_dispatch)  
2. Retrieves the list of artifacts from the GitHub API  
3. Selects the **latest artifact** via a Code node  
4. Downloads the Excel artifact  
5. Optionally emails it via Gmail node  
6. Makes the file downloadable inside n8n  
7. Supports scheduled runs (Cron)

This provides a no-code UI for automated report delivery.

---

# ğŸ”§ Execution Options (Flexible by Design)

This pipeline intentionally supports **three execution styles**:

### **1) Local Python run**
```bash
python html_table_scraper.py
```
Scrapes â†’ cleans â†’ exports â†’ emails.

### **2) GitHub Actions (manual trigger)**
From the Actions tab:
- Click **Run workflow**  
- The workflow runs the script in CI and uploads the Excel as an artifact.

### **3) n8n workflow**
- Can run on a schedule (daily)  
- Can run manually (single click)  
- Automatically fetches the latest Excel artifact  
- Can email the Excel again  
- Allows direct downloading in the n8n UI

All three methods produce the **same Excel output**.

---

# ğŸ“ Project Structure

```
html-table-scraper-gmail-automation/
â”‚
â”œâ”€â”€ html_table_scraper.py               # scrape â†’ clean â†’ Excel â†’ email
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ README.md                           # Main documentation
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ largest_companies_by_revenue.xlsx   # Real Excel output
â”‚
â”œâ”€â”€ .env (not committed)                # Local SMTP credentials
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ automation.yml              # GitHub Actions workflow
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ README_N8N.md
    â”œâ”€â”€ html-table-scraper-gmail-automation.json
    â””â”€â”€ automation.png
```

---

# â–¶ï¸ Local Usage

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Add `.env`
```env
SCRAPER_SMTP_USER=your_email@gmail.com
SCRAPER_SMTP_PASSWORD=your_app_password
```

### 3. Run script
```bash
python html_table_scraper.py
```

Produces:

- Excel under `outputs/`  
- Email (if SMTP configured)

---

# ğŸ¾ Notes

- Do **not** commit your `.env`  
- Gmail requires an **App Password**  
- n8n always retrieves the latest artifact  
- GitHub Actions run is manual, but scheduling can be added if needed

---

# ğŸ‘©â€ğŸ’» Author

**Ã–zge GÃ¼neÅŸ**  
Automation â€¢ Python â€¢ Web Scraping â€¢ Data Cleaning â€¢ Workflow Design
