
# **HTML Table Scraper + Excel Export + Gmail Automation**

A fully automated pipeline that **scrapes HTML tables**, **cleans the data**, **exports Excel output**, and **delivers the final file via Gmail** â€” all powered by Python and enhanced with **GitHub Actions automation**.

This repository demonstrates:

- Web scraping  
- Data cleaning  
- Excel export  
- Secure Gmail automation  
- CI workflow with GitHub Actions  
- Artifact-based file delivery (for n8n integration)

---

## ğŸ“ **Project Structure**

```
html-table-scraper-gmail-automation/
â”œâ”€â”€ html_table_scraper.py        # Main Python scraper script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Main documentation (this file)
â”œâ”€â”€ .env                         # Email credentials (not committed)
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ automation.yml       # GitHub Actions automation pipeline
```

> `automation.yml` automatically runs the scraper, generates the Excel file, and uploads it as an artifact.

---

## ğŸš€ **Features**

âœ” Scrapes HTML table data  
âœ” Parses + cleans + normalizes records  
âœ” Saves Excel output  
âœ” Sends final file via Gmail  
âœ” Credential-safe environment via `.env`  
âœ” GitHub Actions triggers script in the cloud  
âœ” Artifact output is downloadable by systems like **n8n**

---

## ğŸ” **Environment Variables**

Create a `.env` file like this:

```
SCRAPER_SMTP_USER=your_email@gmail.com
SCRAPER_SMTP_PASSWORD=your_gmail_app_password
```
- Gmail requires an App Password (16-character code). Your normal account password will NOT work.
---

## âš™ï¸ **GitHub Actions (automation.yml)**

Workflow performs:

1. Install Python & dependencies  
2. Run `html_table_scraper.py`  
3. Save the generated Excel file  
4. Upload Excel as **GitHub Artifact**  
5. Allow external automation tools to fetch the artifact  

Triggered via:

- Manual dispatch  
- n8n Webhook / schedule  
- Cron (if enabled)

---
## ğŸ“¦ Installation

### 1. Clone the repo

```bash
git clone https://github.com/<your-username>/html-table-scraper-automation.git
cd html-table-scraper-automation
```

### 2. Optional: Create a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate   # macOS/Linux
# .\venv\Scripts\activate  # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Script

```bash
python3 html_table_scraper.py
```

Expected output:

```
1) Fetching HTML...
2) Parsing table...
3) Cleaning data...
4) Saving Excel...
Excel saved to: outputs/largest_companies_by_revenue.xlsx
5) Sending email...
ğŸ“§ Email sent successfully!
ğŸ‰ ALL DONE â€” Automated Pipeline Completed.
```

If SMTP credentials are missing:

```
âš  SMTP credentials not found in environment. Skipping email sending.
```

---

## ğŸ“§ Gmail SMTP Setup

To allow email sending:

âœ” Enable 2-Step Verification  
âœ” Generate a 16-character App Password  
âœ” Put it inside `.env`  

Your actual Gmail password is never used or exposed.

---

## ğŸ”„ Extensions

- Scrape multiple tables  
- Create daily/weekly auto-reports  
- Upload Excel to Google Drive  
- Add KPIs, charts, or analytics  
- Turn the workflow into an automated n8n pipeline  

---
## ğŸ”— Additional Documentation

Even when the file is successfully delivered via e-mail, the latest Excel output can still be downloaded directly from n8n as well.

ğŸ“˜ n8n Automation Docs â†’ [docs/README_N8N.md](docs/README_N8N.md)

## ğŸ‘©â€ğŸ’» Author

**Ã–zge GÃ¼neÅŸ**  
Python Automation Â· Web Scraping Â· Data Cleaning Â· Process Automation  
